{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings and textual similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to replicate the experimental results on textual similarity tasks from **A Simple but Tough-to-Beat Baseline for Sentence Embeddings** (Arora *et al*. 2017, https://openreview.net/pdf?id=SyK00v5xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Textual Similarity (STS) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SemEval](http://alt.qcri.org/semeval2016/) data are obtained from the `datasets-sts` repo: https://github.com/brmson/dataset-sts\n",
    "\n",
    "`pysts` (included in this repo) can be used to load STS tasks data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./dataset-sts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysts\n",
    "from pysts.loader import load_sts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the headlines dataset of SemEval 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives two lists of lists of the sentences (`s0` and `s1`), and the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'foundations',\n",
       " 'of',\n",
       " 'South',\n",
       " 'Africa',\n",
       " 'are',\n",
       " 'built',\n",
       " 'on',\n",
       " 'Nelson',\n",
       " 'Mandela',\n",
       " \"'s\",\n",
       " 'memory']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australian',\n",
       " 'politicians',\n",
       " 'lament',\n",
       " 'over',\n",
       " 'Nelson',\n",
       " 'Mandela',\n",
       " \"'s\",\n",
       " 'death']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it excluded those pair of sentences that had not a label (can also use `skip_unlabeled=False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe pre-trained word vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe - Global Vectors for Word Representation (https://nlp.stanford.edu/projects/glove/). Pre-trained word vectors have been downloaded (we use the 300-dimensional vectors trained on the 840 billion token Common Crawl corpus: http://nlp.stanford.edu/data/glove.840B.300d.zip), and converted to a dictionary for further usage:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import zipfile\n",
    "    \n",
    "    z = zipfile.ZipFile(\"./glove.840B.300d.zip\")\n",
    "    glove = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove2 = {key: val.values for key, val in glove.T.items()}\n",
    "    \n",
    "    import pickle\n",
    "    with open('glove.840B.300d.pkl', 'wb') as output:\n",
    "        pickle.dump(glove2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('glove.840B.300d.pkl', 'rb') as pkl:\n",
    "    glove = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the 300 D array for 'python':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.035414, -0.4573  ,  0.42617 ,  0.23448 ,  0.18446 ,  0.78676 ,\n",
       "        0.15513 , -0.41701 ,  0.36996 , -0.25015 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the methods below, we also need the word frequencies estimated from the corpus. As we currently don't have this available for the GloVe pretrained vectors / Common Crawl corpus, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.981071705534969e-06"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('python', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022908676527677734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('and', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict similarity between sentences (STS tasks) based on GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the similarity between two sentences, the word embeddings (using the GloVe word vectors) are combined into a sentence embedding. \n",
    "\n",
    "Similarity is calculate as the cosine similarity of the two sentence embeddings, and the performance is evaluated as the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg-GloVe: unweighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple method is to take the unweighted average of the different word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_vector_avg(sentence):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            word_vecs.append(np.array(glove[token]))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity between two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v0 = sentence_vector_avg(s0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = sentence_vector_avg(s1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73405983546708098"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity for the full set of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vs0 = embed_avg(s0)\n",
    "Vs1 = embed_avg(s1)\n",
    "predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9983c95d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwYmbEEKGDE7chBAyZHDiJoSQIeP/A1OoO474+clsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9983ced3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(predicted, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation criterion is the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66095534976480941"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(predicted, labels)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systematically on all STS tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tasks(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        Vs0 = embed_func(s0)\n",
    "        Vs1 = embed_func(s1)\n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset-sts/data/sts/semeval-sts/all/2012.MSRpar.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTeuroparl.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTnews.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.FNWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-forum.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.tweet-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-forums.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-students.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.belief.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.answer-answer.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.plagiarism.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.postediting.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.question-question.test.tsv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"dataset-sts/data/sts/semeval-sts/all/*.test.tsv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files.remove('dataset-sts/data/sts/semeval-sts/all/2015.test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg = evaluate_tasks(files, embed_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = res_avg.to_frame(name='avg-GloVe') * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe\n",
       "2012 MSRpar                  43.4\n",
       "     OnWN                    56.7\n",
       "     SMTeuroparl             41.2\n",
       "     SMTnews                 46.7\n",
       "2013 FNWN                    38.0\n",
       "     OnWN                    47.1\n",
       "     headlines               63.1\n",
       "2014 OnWN                    57.6\n",
       "     deft-forum              27.8\n",
       "     deft-news               65.0\n",
       "     headlines               59.3\n",
       "     images                  62.4\n",
       "     tweet-news              54.7\n",
       "2015 answers-forums          34.4\n",
       "     answers-students        63.1\n",
       "     belief                  44.1\n",
       "     headlines               66.1\n",
       "     images                  69.1\n",
       "2016 answer-answer           38.3\n",
       "     headlines               61.1\n",
       "     plagiarism              52.6\n",
       "     postediting             54.4\n",
       "     question-question       48.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe\n",
       "2012       47.0\n",
       "2013       49.4\n",
       "2014       54.4\n",
       "2015       55.4\n",
       "2016       51.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe+W: weighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Arora *et al.* (2017) paper, a weighted average of the word vectors (smooth inverse frequency weighting) is used based on word frequencies estimated from the commoncrawl dataset. Here, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/) as alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wordfreq\n",
    "\n",
    "def sentence_vector_avg_W(sentence, a=1e-3):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            vw = np.array(glove[token])\n",
    "            freq = wordfreq.word_frequency(token, 'en', wordlist='large')\n",
    "            vw *= a / (a + freq)\n",
    "            word_vecs.append(vw)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg_W(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg_W = evaluate_tasks(files, embed_avg_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W], keys=['avg-GloVe', 'GloVe+W'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "      <td>56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "      <td>66.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W\n",
       "2012 MSRpar                  43.4     40.5\n",
       "     OnWN                    56.7     61.0\n",
       "     SMTeuroparl             41.2     46.2\n",
       "     SMTnews                 46.7     50.9\n",
       "2013 FNWN                    38.0     39.5\n",
       "     OnWN                    47.1     65.5\n",
       "     headlines               63.1     66.2\n",
       "2014 OnWN                    57.6     70.8\n",
       "     deft-forum              27.8     31.9\n",
       "     deft-news               65.0     69.8\n",
       "     headlines               59.3     62.0\n",
       "     images                  62.4     76.4\n",
       "     tweet-news              54.7     58.6\n",
       "2015 answers-forums          34.4     46.7\n",
       "     answers-students        63.1     66.0\n",
       "     belief                  44.1     56.8\n",
       "     headlines               66.1     69.5\n",
       "     images                  69.1     76.7\n",
       "2016 answer-answer           38.3     49.0\n",
       "     headlines               61.1     65.6\n",
       "     plagiarism              52.6     68.8\n",
       "     postediting             54.4     66.2\n",
       "     question-question       48.5     64.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "      <td>61.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W\n",
       "2012       47.0     49.7\n",
       "2013       49.4     57.1\n",
       "2014       54.4     61.6\n",
       "2015       55.4     63.1\n",
       "2016       51.0     62.7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The weighting scheme considerably improves the similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the GloVe+WR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average from above, but now combined with a removal of the common components, from Arora *et al.* (2017) (https://openreview.net/pdf?id=SyK00v5xx)\n",
    "\n",
    "The algorithm for sentence embedding (Algorithm 1, page 6, Arora et al. 2017):\n",
    "\n",
    "> **Input** Word embeddings $\\{v_w : w \\in \\mathcal{V}\\}$, a set of sentences $\\mathcal{S}$, parameter $a$ and estimated probabilities $\\{p(w) : w \\in \\mathcal{V}\\}$.  \n",
    "> **Output**: Sentence embeddings $\\{v_s : s \\in \\mathcal{S}\\}$\n",
    ">\n",
    "> 1: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 2: $ \\phantom{...} v_s \\gets \\frac{1}{|s|} \\sum_{w \\in s}{\\frac{a}{a + p(w)} v_w}$  \n",
    "> 3: **end for**  \n",
    "> 4: Compute the first principal component $u$ of $\\{v_s : s \\in \\mathcal{S}\\}$  \n",
    "> 5: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 6: $ \\phantom{...} v_s \\gets v_s - u u^T v_s$  \n",
    "> 7: **end for**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average to obtain the sentence embeddings $v_s$ (lines 1-3 in the algorithm) is the same as above (using `sentence_vector_avg_W`), but now afterwards the full matrix of those vectors is further adapted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "def embed_avg_WR(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the weighted average of the word vectors +\n",
    "    applying subtraction of first principal component projection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted average of word vectors for all sentences\n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    X = np.array(values)\n",
    "    \n",
    "    # removal of common component\n",
    "    #pca = PCA(n_components=1).fit(X)\n",
    "    #u = pca.components_#[0]\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=1, n_iter=7, random_state=0).fit(X)\n",
    "    u = svd.components_[0]\n",
    "    \n",
    "    return X - np.dot(X, np.outer(u, u))\n",
    "    \n",
    "    #return X - X.dot(u.transpose()) * u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to evaluate on all tasks is slightly adapted, as we do the embedding (and thus component removal) on all sentences (both left and right sentences) together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tasks2(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        \n",
    "        # combine left and right sentences, embed, and split again\n",
    "        s0 = np.array(s0)\n",
    "        s1 = np.array(s1)\n",
    "        embedded = embed_func(np.concatenate((s0, s1), axis=0))\n",
    "        Vs0 = embedded[:s0.shape[0]]\n",
    "        Vs1 = embedded[s0.shape[0]:]\n",
    "        \n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg_WR = evaluate_tasks(files, embed_avg_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W, res_avg_WR], keys=['avg-GloVe', 'GloVe+W', 'GloVe+WR'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "      <td>40.5</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "      <td>46.2</td>\n",
       "      <td>49.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "      <td>50.9</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>42.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.2</td>\n",
       "      <td>70.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "      <td>70.8</td>\n",
       "      <td>82.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "      <td>31.9</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "      <td>76.4</td>\n",
       "      <td>82.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "      <td>58.6</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "      <td>46.7</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>72.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>74.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "      <td>76.7</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "      <td>65.6</td>\n",
       "      <td>70.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "      <td>68.8</td>\n",
       "      <td>78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "      <td>66.2</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012 MSRpar                  43.4     40.5      33.8\n",
       "     OnWN                    56.7     61.0      67.2\n",
       "     SMTeuroparl             41.2     46.2      49.1\n",
       "     SMTnews                 46.7     50.9      50.9\n",
       "2013 FNWN                    38.0     39.5      42.5\n",
       "     OnWN                    47.1     65.5      80.5\n",
       "     headlines               63.1     66.2      70.7\n",
       "2014 OnWN                    57.6     70.8      82.5\n",
       "     deft-forum              27.8     31.9      37.7\n",
       "     deft-news               65.0     69.8      69.4\n",
       "     headlines               59.3     62.0      65.9\n",
       "     images                  62.4     76.4      82.8\n",
       "     tweet-news              54.7     58.6      70.4\n",
       "2015 answers-forums          34.4     46.7      65.0\n",
       "     answers-students        63.1     66.0      71.9\n",
       "     belief                  44.1     56.8      72.7\n",
       "     headlines               66.1     69.5      74.2\n",
       "     images                  69.1     76.7      81.5\n",
       "2016 answer-answer           38.3     49.0      52.1\n",
       "     headlines               61.1     65.6      70.2\n",
       "     plagiarism              52.6     68.8      78.1\n",
       "     postediting             54.4     66.2      80.0\n",
       "     question-question       48.5     64.0      69.4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "      <td>49.7</td>\n",
       "      <td>50.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "      <td>61.6</td>\n",
       "      <td>68.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "      <td>63.1</td>\n",
       "      <td>73.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012       47.0     49.7      50.2\n",
       "2013       49.4     57.1      64.5\n",
       "2014       54.4     61.6      68.1\n",
       "2015       55.4     63.1      73.1\n",
       "2016       51.0     62.7      70.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The removal of the common component based on the first singular vector clearly further improves the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try out, instead of using the SVD first singular vector, let's rescale the sentence embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_avg_WR_2(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the weighted average of the word vectors +\n",
    "    applying subtraction of first principal component projection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted average of word vectors for all sentences\n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    X = np.array(values)\n",
    "    \n",
    "    # rescale\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg_WR_2 = evaluate_tasks(files, embed_avg_WR_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W, res_avg_WR, res_avg_WR_2],\n",
    "                keys=['avg-GloVe', 'GloVe+W', 'GloVe+WR', 'GloVe+W+Scale'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "      <th>GloVe+W+Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "      <td>49.7</td>\n",
       "      <td>50.2</td>\n",
       "      <td>52.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>64.5</td>\n",
       "      <td>66.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "      <td>61.6</td>\n",
       "      <td>68.1</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "      <td>63.1</td>\n",
       "      <td>73.1</td>\n",
       "      <td>74.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W  GloVe+WR  GloVe+W+Scale\n",
       "2012       47.0     49.7      50.2           52.6\n",
       "2013       49.4     57.1      64.5           66.7\n",
       "2014       54.4     61.6      68.1           69.4\n",
       "2015       55.4     63.1      73.1           74.2\n",
       "2016       51.0     62.7      70.0           71.5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe th {\n",
       "  vertical-align: top;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style type=\"text/css\">\n",
    "table.dataframe th {\n",
    "  vertical-align: top;\n",
    "}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
