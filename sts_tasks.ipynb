{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence embeddings and textual similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to replicate the experimental results on textual similarity tasks from **A Simple but Tough-to-Beat Baseline for Sentence Embeddings** (Arora *et al*. 2017, https://openreview.net/pdf?id=SyK00v5xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Textual Similarity (STS) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SemEval](http://alt.qcri.org/semeval2016/) data are obtained from the `datasets-sts` repo: https://github.com/brmson/dataset-sts\n",
    "\n",
    "`pysts` (included in this repo) can be used to load STS tasks data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./dataset-sts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysts\n",
    "from pysts.loader import load_sts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the headlines dataset of SemEval 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives two lists of lists of the sentences (`s0` and `s1`), and the corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'foundations',\n",
       " 'of',\n",
       " 'South',\n",
       " 'Africa',\n",
       " 'are',\n",
       " 'built',\n",
       " 'on',\n",
       " 'Nelson',\n",
       " 'Mandela',\n",
       " \"'s\",\n",
       " 'memory']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australian',\n",
       " 'politicians',\n",
       " 'lament',\n",
       " 'over',\n",
       " 'Nelson',\n",
       " 'Mandela',\n",
       " \"'s\",\n",
       " 'death']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, it excluded those pair of sentences that had not a label (can also use `skip_unlabeled=False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s0, s1, labels = load_sts(\"dataset-sts/data/sts/semeval-sts/2015/headlines.test.tsv\", skip_unlabeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe pre-trained word vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe - Global Vectors for Word Representation (https://nlp.stanford.edu/projects/glove/). Pre-trained word vectors have been downloaded (we use the 300-dimensional vectors trained on the 840 billion token Common Crawl corpus: http://nlp.stanford.edu/data/glove.840B.300d.zip), and converted to a dictionary for further usage:\n",
    "    \n",
    "    import pandas as pd\n",
    "    import zipfile\n",
    "    \n",
    "    z = zipfile.ZipFile(\"./glove.840B.300d.zip\")\n",
    "    glove = pd.read_csv(z.open('glove.840B.300d.txt'), sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove2 = {key: val.values for key, val in glove.T.items()}\n",
    "    \n",
    "    import pickle\n",
    "    with open('glove.840B.300d.pkl', 'wb') as output:\n",
    "        pickle.dump(glove2, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('glove.840B.300d.pkl', 'rb') as pkl:\n",
    "    glove = pickle.load(pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the 300 D array for 'python':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.54140000e-02,  -4.57300000e-01,   4.26170000e-01,\n",
       "         2.34480000e-01,   1.84460000e-01,   7.86760000e-01,\n",
       "         1.55130000e-01,  -4.17010000e-01,   3.69960000e-01,\n",
       "        -2.50150000e-01,  -5.07050000e-01,  -6.14740000e-01,\n",
       "         3.06840000e-01,   2.85050000e-02,  -7.52220000e-01,\n",
       "         5.97250000e-02,  -4.04680000e-01,   9.49240000e-01,\n",
       "         2.31870000e-01,  -5.89560000e-01,  -5.56220000e-01,\n",
       "         3.84040000e-01,  -4.86240000e-01,   1.11380000e-01,\n",
       "        -4.85440000e-01,   2.49060000e-01,   9.60680000e-02,\n",
       "         2.03090000e-01,   5.13880000e-01,  -3.84310000e-01,\n",
       "         5.33230000e-02,  -8.35660000e-01,   1.87020000e-01,\n",
       "        -2.63540000e-01,  -3.69070000e-01,  -7.20300000e-02,\n",
       "         3.95150000e-01,  -2.90800000e-01,  -5.81550000e-01,\n",
       "        -2.31310000e-01,   8.52490000e-01,  -2.33080000e-01,\n",
       "        -1.67290000e-01,   7.08240000e-02,  -2.28030000e-02,\n",
       "         2.12520000e-01,  -1.99560000e-01,   1.65670000e-01,\n",
       "         7.25320000e-02,  -2.26180000e-01,  -5.09860000e-01,\n",
       "        -2.66940000e-01,  -4.70070000e-02,  -7.98270000e-01,\n",
       "         7.19630000e-04,   5.19410000e-02,   8.15000000e-02,\n",
       "        -6.03290000e-01,  -2.46510000e-01,   5.84430000e-02,\n",
       "        -6.32830000e-01,   1.56710000e-01,  -2.26270000e-01,\n",
       "        -5.49550000e-01,   2.20710000e-01,  -5.14010000e-02,\n",
       "         6.31330000e-01,   2.24190000e-01,   6.01040000e-01,\n",
       "         3.43660000e-02,   2.82460000e-01,  -5.73980000e-01,\n",
       "        -1.17910000e-01,  -1.75690000e-01,   1.36770000e-01,\n",
       "        -2.43420000e-01,  -7.62990000e-02,   1.49820000e-01,\n",
       "        -1.76100000e-01,  -4.87210000e-01,  -7.44400000e-01,\n",
       "         4.83210000e-01,   1.86390000e-01,   5.78980000e-02,\n",
       "        -2.94140000e-01,   5.20180000e-01,   1.03800000e+00,\n",
       "         1.33680000e-01,   3.47300000e-01,   3.54340000e-03,\n",
       "        -2.61030000e-01,   2.59690000e-01,  -4.93500000e-01,\n",
       "        -4.72800000e-01,   5.11990000e-01,   2.87270000e-01,\n",
       "        -4.01510000e-01,   4.21020000e-02,   3.81330000e-01,\n",
       "        -2.06970000e-01,  -1.42380000e-01,   5.95200000e-01,\n",
       "        -1.92600000e-01,   2.45030000e-02,  -2.15490000e-01,\n",
       "        -1.17010000e+00,   4.34620000e-01,   7.02930000e-01,\n",
       "        -3.85890000e-01,  -3.44780000e-01,  -6.13700000e-01,\n",
       "        -2.06520000e-01,   1.24210000e-01,  -5.08820000e-01,\n",
       "        -5.43090000e-01,   3.35230000e-01,   1.68080000e-01,\n",
       "        -1.85330000e-01,   1.04680000e-01,   1.70480000e-01,\n",
       "         3.98150000e-01,  -1.02670000e+00,   5.11540000e-01,\n",
       "        -6.95960000e-01,  -1.17890000e-01,   4.17900000e-02,\n",
       "        -4.77780000e-02,   5.08320000e-01,   6.61760000e-02,\n",
       "        -1.81530000e-01,   1.39290000e-01,   3.77680000e-01,\n",
       "        -5.72710000e-01,  -6.82490000e-03,  -1.00710000e-02,\n",
       "         2.17530000e-01,   3.38780000e-01,  -2.20410000e-01,\n",
       "         1.22830000e-01,   1.91300000e-01,  -1.78050000e+00,\n",
       "        -3.81300000e-01,  -3.28180000e-01,   3.46270000e-01,\n",
       "         4.22120000e-01,   1.24090000e-01,   6.62790000e-03,\n",
       "        -3.59450000e-01,   1.28110000e-01,  -1.17790000e-01,\n",
       "         7.32110000e-01,  -1.26920000e-01,  -7.73140000e-02,\n",
       "         3.23060000e-01,  -5.59670000e-01,  -1.72350000e-01,\n",
       "        -2.50980000e-01,  -1.52580000e-01,   4.22130000e-01,\n",
       "         4.09080000e-01,  -8.79100000e-02,   2.51950000e-01,\n",
       "        -2.26340000e-01,  -2.63600000e-01,   9.25280000e-02,\n",
       "         6.90220000e-01,  -3.26150000e-01,  -8.76230000e-01,\n",
       "        -1.67660000e-01,  -1.21140000e-01,   3.40260000e-01,\n",
       "         6.64440000e-01,   3.32250000e-01,  -3.98510000e-01,\n",
       "        -8.60530000e-01,   6.03380000e-01,  -1.54150000e-01,\n",
       "        -5.07440000e-02,   3.17720000e-01,  -1.19760000e-02,\n",
       "         7.50980000e-01,  -6.36850000e-01,  -6.75330000e-01,\n",
       "        -4.74820000e-01,  -1.82940000e-01,  -9.17620000e-02,\n",
       "         7.29900000e-03,   2.47670000e-01,  -3.78100000e-01,\n",
       "         1.72740000e-01,  -3.75810000e-01,  -2.16430000e-01,\n",
       "        -8.30530000e-02,   1.06150000e-03,   8.05820000e-01,\n",
       "         2.11410000e-01,  -3.22600000e-01,  -1.70000000e-01,\n",
       "         4.18950000e-01,  -6.65190000e-01,  -4.45700000e-01,\n",
       "         1.06020000e-01,  -1.14790000e-01,   7.38110000e-01,\n",
       "         3.13890000e-02,  -5.70090000e-01,  -3.56930000e-01,\n",
       "         2.55040000e-01,  -5.00440000e-01,  -1.03080000e-01,\n",
       "        -1.32580000e-01,  -4.18040000e-01,  -1.37880000e-01,\n",
       "        -3.67920000e-01,  -4.10790000e-01,  -3.05560000e-01,\n",
       "        -8.55900000e-01,  -3.49610000e-01,  -4.77140000e-01,\n",
       "        -3.17500000e-01,   4.41780000e-02,   4.84640000e-01,\n",
       "        -1.57030000e-01,   2.94930000e-01,   5.39450000e-01,\n",
       "         1.20130000e-01,   5.73450000e-01,   3.00000000e-01,\n",
       "        -2.86290000e-01,   5.44140000e-01,   1.73770000e-02,\n",
       "        -7.03070000e-02,  -2.84270000e-01,  -3.30820000e-01,\n",
       "        -3.48820000e-01,   4.06580000e-01,  -5.61320000e-01,\n",
       "         1.18700000e-01,   8.00260000e-01,   1.36560000e-01,\n",
       "         8.23160000e-02,  -3.70470000e-01,   1.66570000e-03,\n",
       "        -5.50280000e-01,   3.68030000e-01,  -9.26100000e-01,\n",
       "         6.05980000e-01,   2.57320000e-01,   2.18600000e-01,\n",
       "        -2.18720000e-01,  -4.43120000e-01,   6.63380000e-01,\n",
       "        -2.07030000e-01,  -2.47780000e-03,   6.18600000e-01,\n",
       "        -2.29360000e-01,   1.80830000e-01,   1.78000000e-01,\n",
       "         5.91480000e-01,  -1.05040000e+00,   3.00240000e-01,\n",
       "         4.84990000e-01,   2.64400000e-01,   1.26440000e-01,\n",
       "         1.85630000e-01,   1.19050000e-01,  -3.62820000e-02,\n",
       "         2.84750000e-01,   5.84810000e-01,  -5.08270000e-02,\n",
       "        -4.15760000e-01,  -1.61630000e-02,   2.73600000e-01,\n",
       "        -2.47740000e-01,  -5.30320000e-02,  -3.96030000e-01,\n",
       "         3.65880000e-01,  -1.85350000e-01,  -3.01280000e-01,\n",
       "        -3.94270000e-01,   2.70360000e-01,   8.05880000e-02,\n",
       "         5.59330000e-01,   1.12790000e-01,   2.90880000e-02,\n",
       "        -1.31250000e+00,   7.16080000e-03,  -3.35130000e-01,\n",
       "         2.12030000e-01,  -7.10010000e-01,   3.72880000e-01,\n",
       "        -5.20980000e-01,  -8.34150000e-01,   4.49830000e-01,\n",
       "         7.93140000e-02,   7.26560000e-01,   9.04870000e-02,\n",
       "         6.66400000e-02,  -4.32840000e-01,   1.48020000e-01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['python']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the methods below, we also need the word frequencies estimated from the corpus. As we currently don't have this available for the GloVe pretrained vectors / Common Crawl corpus, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.981071705534969e-06"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('python', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022908676527677734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq.word_frequency('and', 'en', wordlist='large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict similarity between sentences (STS tasks) based on GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the similarity between two sentences, the word embeddings (using the GloVe word vectors) are combined into a sentence embedding. \n",
    "\n",
    "Similarity is calculate as the cosine similarity of the two sentence embeddings, and the performance is evaluated as the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avg-GloVe: unweighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple method is to take the unweighted average of the different word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_vector_avg(sentence):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            word_vecs.append(np.array(glove[token]))\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity between two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v0 = sentence_vector_avg(s0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = sentence_vector_avg(s1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73405983546708098"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(v0, v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict similarity for the full set of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vs0 = embed_avg(s0)\n",
    "Vs1 = embed_avg(s1)\n",
    "predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f46361cbc50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwYmbEEKGDE7chBAyZHDiJoSQIeP/A1OoO474+clsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4636224ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(predicted, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation criterion is the Pearson's coefficient between the predicted scores and the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66095534976480941"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(predicted, labels)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systematically on all STS tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tasks(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        Vs0 = embed_func(s0)\n",
    "        Vs1 = embed_func(s1)\n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset-sts/data/sts/semeval-sts/all/2012.MSRpar.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTeuroparl.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2012.SMTnews.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.FNWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2013.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.OnWN.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-forum.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.deft-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2014.tweet-news.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-forums.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.answers-students.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.belief.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.images.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2015.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.answer-answer.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.headlines.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.plagiarism.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.postediting.test.tsv',\n",
       " 'dataset-sts/data/sts/semeval-sts/all/2016.question-question.test.tsv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"dataset-sts/data/sts/semeval-sts/all/*.test.tsv\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files.remove('dataset-sts/data/sts/semeval-sts/all/2015.test.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg = evaluate_tasks(files, embed_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = res_avg.to_frame(name='avg-GloVe') * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe\n",
       "2012 MSRpar                  43.4\n",
       "     OnWN                    56.7\n",
       "     SMTeuroparl             41.2\n",
       "     SMTnews                 46.7\n",
       "2013 FNWN                    38.0\n",
       "     OnWN                    47.1\n",
       "     headlines               63.1\n",
       "2014 OnWN                    57.6\n",
       "     deft-forum              27.8\n",
       "     deft-news               65.0\n",
       "     headlines               59.3\n",
       "     images                  62.4\n",
       "     tweet-news              54.7\n",
       "2015 answers-forums          34.4\n",
       "     answers-students        63.1\n",
       "     belief                  44.1\n",
       "     headlines               66.1\n",
       "     images                  69.1\n",
       "2016 answer-answer           38.3\n",
       "     headlines               61.1\n",
       "     plagiarism              52.6\n",
       "     postediting             54.4\n",
       "     question-question       48.5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe\n",
       "2012       47.0\n",
       "2013       49.4\n",
       "2014       54.4\n",
       "2015       55.4\n",
       "2016       51.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe+W: weighted average of GloVe vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Arora *et al.* (2017) paper, a weighted average of the word vectors (smooth inverse frequency weighting) is used based on word frequencies estimated from the commoncrawl dataset. Here, we use the `wordfreq` package (https://github.com/LuminosoInsight/wordfreq/) as alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wordfreq\n",
    "\n",
    "def sentence_vector_avg_W(sentence, a=1e-3):\n",
    "    \"\"\"Calculate the sentence vector as the mean of the word vectors\"\"\"\n",
    "    \n",
    "    word_vecs = []\n",
    "    for token in sentence:\n",
    "        token = token.lower()\n",
    "        try:\n",
    "            vw = np.array(glove[token])\n",
    "            freq = wordfreq.word_frequency(token, 'en', wordlist='large')\n",
    "            vw *= a / (a + freq)\n",
    "            word_vecs.append(vw)\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return np.array(word_vecs).mean(axis=0)\n",
    "\n",
    "def embed_avg_W(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the average of the word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    return np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg_W = evaluate_tasks(files, embed_avg_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W], keys=['avg-GloVe', 'GloVe+W'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "      <td>70.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "      <td>69.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "      <td>56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "      <td>76.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "      <td>68.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "      <td>66.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W\n",
       "2012 MSRpar                  43.4     40.5\n",
       "     OnWN                    56.7     61.0\n",
       "     SMTeuroparl             41.2     46.2\n",
       "     SMTnews                 46.7     50.9\n",
       "2013 FNWN                    38.0     39.5\n",
       "     OnWN                    47.1     65.5\n",
       "     headlines               63.1     66.2\n",
       "2014 OnWN                    57.6     70.8\n",
       "     deft-forum              27.8     31.9\n",
       "     deft-news               65.0     69.8\n",
       "     headlines               59.3     62.0\n",
       "     images                  62.4     76.4\n",
       "     tweet-news              54.7     58.6\n",
       "2015 answers-forums          34.4     46.7\n",
       "     answers-students        63.1     66.0\n",
       "     belief                  44.1     56.8\n",
       "     headlines               66.1     69.5\n",
       "     images                  69.1     76.7\n",
       "2016 answer-answer           38.3     49.0\n",
       "     headlines               61.1     65.6\n",
       "     plagiarism              52.6     68.8\n",
       "     postediting             54.4     66.2\n",
       "     question-question       48.5     64.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "      <td>61.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "      <td>62.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W\n",
       "2012       47.0     49.7\n",
       "2013       49.4     57.1\n",
       "2014       54.4     61.6\n",
       "2015       55.4     63.1\n",
       "2016       51.0     62.7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The weighting scheme considerably improves the similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the GloVe+WR method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average from above, but now combined with a removal of the common components, from Arora *et al.* (2017) (https://openreview.net/pdf?id=SyK00v5xx)\n",
    "\n",
    "The algorithm for sentence embedding (Algorithm 1, page 6, Arora et al. 2017):\n",
    "\n",
    "> **Input** Word embeddings $\\{v_w : w \\in \\mathcal{V}\\}$, a set of sentences $\\mathcal{S}$, parameter $a$ and estimated probabilities $\\{p(w) : w \\in \\mathcal{V}\\}$.  \n",
    "> **Output**: Sentence embeddings $\\{v_s : s \\in \\mathcal{S}\\}$\n",
    ">\n",
    "> 1: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 2: $ \\phantom{...} v_s \\gets \\frac{1}{|s|} \\sum_{w \\in s}{\\frac{a}{a + p(w)} v_w}$  \n",
    "> 3: **end for**  \n",
    "> 4: Compute the first principal component $u$ of $\\{v_s : s \\in \\mathcal{S}\\}$  \n",
    "> 5: **for all** sentence $s$ in $\\mathcal{S}$ **do**  \n",
    "> 6: $ \\phantom{...} v_s \\gets v_s - u u^T v_s$  \n",
    "> 7: **end for**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted average to obtain the sentence embeddings $v_s$ (lines 1-3 in the algorithm) is the same as above (using `sentence_vector_avg_W`), but now afterwards the full matrix of those vectors is further adapted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def embed_avg_WR(sentences):\n",
    "    \"\"\"Calculate sentence embeddings for set of sentences\n",
    "    based on the weighted average of the word vectors +\n",
    "    applying subtraction of first principal component projection.\n",
    "    \"\"\"\n",
    "    \n",
    "    # weighted average of word vectors for all sentences\n",
    "    values = []\n",
    "    for s in sentences:\n",
    "        mean = sentence_vector_avg_W(s)\n",
    "        values.append(mean)\n",
    "        \n",
    "    X = np.array(values)\n",
    "    \n",
    "    # removal of common component\n",
    "    pca = PCA(n_components=1).fit(X)\n",
    "    u = pca.components_[0]\n",
    "    return X - np.dot(X, np.outer(u, u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to evaluate on all tasks is slightly adapted, as we do the embedding (and thus component removal) on all sentences (both left and right sentences) together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tasks2(files, embed_func):\n",
    "\n",
    "    tests = []\n",
    "    scores = []\n",
    "\n",
    "    for f in files:\n",
    "        s0, s1, labels = load_sts(f)\n",
    "        \n",
    "        # combine left and right sentences, embed, and split again\n",
    "        s0 = np.array(s0)\n",
    "        s1 = np.array(s1)\n",
    "        embedded = embed_func(np.concatenate((s0, s1), axis=0))\n",
    "        Vs0 = embedded[:s0.shape[0]]\n",
    "        Vs1 = embedded[s0.shape[0]:]\n",
    "        \n",
    "        predicted = np.array([cosine_similarity(vs0, vs1) for vs0, vs1 in zip(Vs0, Vs1)])\n",
    "        rp = pearsonr(predicted, labels)[0]\n",
    "\n",
    "        scores.append(rp)\n",
    "        name = f.split('/')[-1].split('.')\n",
    "        tests.append((name[0], name[1]))\n",
    "    \n",
    "    return pd.Series(scores, index=pd.MultiIndex.from_tuples(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_avg_WR = evaluate_tasks(files, embed_avg_WR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.concat([res_avg, res_avg_W, res_avg_WR], keys=['avg-GloVe', 'GloVe+W', 'GloVe+WR'], axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2012</th>\n",
       "      <th>MSRpar</th>\n",
       "      <td>43.4</td>\n",
       "      <td>40.5</td>\n",
       "      <td>46.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>56.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTeuroparl</th>\n",
       "      <td>41.2</td>\n",
       "      <td>46.2</td>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTnews</th>\n",
       "      <td>46.7</td>\n",
       "      <td>50.9</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2013</th>\n",
       "      <th>FNWN</th>\n",
       "      <td>38.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>37.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OnWN</th>\n",
       "      <td>47.1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.2</td>\n",
       "      <td>67.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">2014</th>\n",
       "      <th>OnWN</th>\n",
       "      <td>57.6</td>\n",
       "      <td>70.8</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-forum</th>\n",
       "      <td>27.8</td>\n",
       "      <td>31.9</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deft-news</th>\n",
       "      <td>65.0</td>\n",
       "      <td>69.8</td>\n",
       "      <td>71.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>59.3</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>62.4</td>\n",
       "      <td>76.4</td>\n",
       "      <td>75.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet-news</th>\n",
       "      <td>54.7</td>\n",
       "      <td>58.6</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015</th>\n",
       "      <th>answers-forums</th>\n",
       "      <td>34.4</td>\n",
       "      <td>46.7</td>\n",
       "      <td>42.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answers-students</th>\n",
       "      <td>63.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>belief</th>\n",
       "      <td>44.1</td>\n",
       "      <td>56.8</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>66.1</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>69.1</td>\n",
       "      <td>76.7</td>\n",
       "      <td>72.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016</th>\n",
       "      <th>answer-answer</th>\n",
       "      <td>38.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headlines</th>\n",
       "      <td>61.1</td>\n",
       "      <td>65.6</td>\n",
       "      <td>65.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plagiarism</th>\n",
       "      <td>52.6</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postediting</th>\n",
       "      <td>54.4</td>\n",
       "      <td>66.2</td>\n",
       "      <td>73.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question-question</th>\n",
       "      <td>48.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012 MSRpar                  43.4     40.5      46.1\n",
       "     OnWN                    56.7     61.0      57.1\n",
       "     SMTeuroparl             41.2     46.2      45.9\n",
       "     SMTnews                 46.7     50.9      43.1\n",
       "2013 FNWN                    38.0     39.5      37.2\n",
       "     OnWN                    47.1     65.5      63.2\n",
       "     headlines               63.1     66.2      67.6\n",
       "2014 OnWN                    57.6     70.8      71.3\n",
       "     deft-forum              27.8     31.9      33.5\n",
       "     deft-news               65.0     69.8      71.1\n",
       "     headlines               59.3     62.0      62.2\n",
       "     images                  62.4     76.4      75.1\n",
       "     tweet-news              54.7     58.6      65.5\n",
       "2015 answers-forums          34.4     46.7      42.7\n",
       "     answers-students        63.1     66.0      64.3\n",
       "     belief                  44.1     56.8      54.2\n",
       "     headlines               66.1     69.5      69.9\n",
       "     images                  69.1     76.7      72.6\n",
       "2016 answer-answer           38.3     49.0      43.4\n",
       "     headlines               61.1     65.6      65.1\n",
       "     plagiarism              52.6     68.8      55.6\n",
       "     postediting             54.4     66.2      73.4\n",
       "     question-question       48.5     64.0      64.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-GloVe</th>\n",
       "      <th>GloVe+W</th>\n",
       "      <th>GloVe+WR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47.0</td>\n",
       "      <td>49.7</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>49.4</td>\n",
       "      <td>57.1</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>54.4</td>\n",
       "      <td>61.6</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>55.4</td>\n",
       "      <td>63.1</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>51.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      avg-GloVe  GloVe+W  GloVe+WR\n",
       "2012       47.0     49.7      48.1\n",
       "2013       49.4     57.1      56.0\n",
       "2014       54.4     61.6      63.1\n",
       "2015       55.4     63.1      60.7\n",
       "2016       51.0     62.7      60.3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.mean(axis=0, level=0).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast with the results in Arora et al., 2017, the GloVe+WR scheme does not further improve the performance compared to the only doing the weighting (GloVe+W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "table.dataframe th {\n",
       "  vertical-align: top;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<style type=\"text/css\">\n",
    "table.dataframe th {\n",
    "  vertical-align: top;\n",
    "}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
